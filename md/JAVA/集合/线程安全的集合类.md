# Java集合的线程安全性

我们平时用的各种*ArrayList*、*ArrayDeque*、*HashMap*、*HashSet*之类的集合工具类，都不是线程安全的。在它们在多线程环境下使用的时候随时可能会BOOM

当然，如果是List和Map的话你可以选择*Vector*、*Hashtable*这俩支持多线程同步的类

# Collections类的包装方法

正常情况下，这样子声明的一个集合是不支持线程安全的（废话）：

```java
    List list = new ArrayList();
```

*Collections*类中，提供了将普通的集合包装转换为线程安全的集合的方法，这样操作：

```java
    List list = new ArrayList();

    List syncList = Collections.synchronizedList(list);
```

现在，syncList就是一个线程安全的List了

同理，Set、Map等都可以这样转换为线程安全的集合，*Collections*提供了如下方法：

![](../PIC/集合-Collections类里的包装方法.png)

就以刚才的List为例，看下这个方法究竟是怎样的：

```java
    public static <T> List<T> synchronizedList(List<T> list) {
        return (list instanceof RandomAccess ?
                new SynchronizedRandomAccessList<>(list) :
                new SynchronizedList<>(list));
    }
```

这里看到，根据传进来的*List*里有没有实现*RandomAccess*接口，分别返回了一个类。其实，看到*return new Xxxx()*心里都有些眉目了

![](../PIC/集合-Collections类里的包装类.png)

*Collections*工具类里有这么多包装类↑↑↑

*ArrayList*是实现了*RandomAccess*接口的，去看一下*SynchronizedRandomAccessList*类是怎样的：

```java
 static class SynchronizedRandomAccessList<E>
        extends SynchronizedList<E>
        implements RandomAccess {

        SynchronizedRandomAccessList(List<E> list) {
            super(list);
        }

        SynchronizedRandomAccessList(List<E> list, Object mutex) {
            super(list, mutex);
        }

        public List<E> subList(int fromIndex, int toIndex) {
            synchronized (mutex) {
                return new SynchronizedRandomAccessList<>(
                    list.subList(fromIndex, toIndex), mutex);
            }
        }

        private static final long serialVersionUID = 1530674583602358482L;

        private Object writeReplace() {
            return new SynchronizedList<>(list);
        }
    }
```

发现它继承了*SynchronizedList*，但是并没有什么特别的。*subList(int fromIndex, int toIndex)* 重写了父类的方法（这里看不出来，IDEA上标记了）。去看看父类是怎样的：

```java
static class SynchronizedList<E>
        extends SynchronizedCollection<E>
        implements List<E> {
        private static final long serialVersionUID = -7754090372962971524L;

        final List<E> list;

        SynchronizedList(List<E> list) {
            super(list);
            this.list = list;
        }
        SynchronizedList(List<E> list, Object mutex) {
            super(list, mutex);
            this.list = list;
        }

        public boolean equals(Object o) {
            if (this == o)
                return true;
            synchronized (mutex) {return list.equals(o);}
        }
        public int hashCode() {
            synchronized (mutex) {return list.hashCode();}
        }
        public E get(int index) {
            synchronized (mutex) {return list.get(index);}
        }
        public E set(int index, E element) {
            synchronized (mutex) {return list.set(index, element);}
        }
        public void add(int index, E element) {
            synchronized (mutex) {list.add(index, element);}
        }
        public E remove(int index) {
            synchronized (mutex) {return list.remove(index);}
        }
        public int indexOf(Object o) {
            synchronized (mutex) {return list.indexOf(o);}
        }
        public int lastIndexOf(Object o) {
            synchronized (mutex) {return list.lastIndexOf(o);}
        }
        public boolean addAll(int index, Collection<? extends E> c) {
            synchronized (mutex) {return list.addAll(index, c);}
        }
        public ListIterator<E> listIterator() {
            return list.listIterator(); // Must be manually synched by user
        }
        public ListIterator<E> listIterator(int index) {
            return list.listIterator(index); // Must be manually synched by user
        }
        public List<E> subList(int fromIndex, int toIndex) {
            synchronized (mutex) {
                return new SynchronizedList<>(list.subList(fromIndex, toIndex), mutex);
            }
        }
        @Override
        public void replaceAll(UnaryOperator<E> operator) {
            synchronized (mutex) {list.replaceAll(operator);}
        }
        @Override
        public void sort(Comparator<? super E> c) {
            synchronized (mutex) {list.sort(c);}
        }
        private Object readResolve() {
            return (list instanceof RandomAccess
                    ? new SynchronizedRandomAccessList<>(list)
                    : this);
        }
    }
```

为了代码完整性这里就不做删减了

追到这里已经差不多明了了，其实*SynchronizedList*将我们传进去的list保存在了自己的成员变量中。*SynchronizedList*基本上所有的操作都是直接调用原来list的方法，只不过使用*synchronized*关键字把它包在了同步块中

而且，这不就是代理模式吗！！！！！！

所以，我们的*Collections.synchronizedList(xxx)*就是给我们返回了一个代理类，通过这个代理类去调用xxx集合，保证多线程同步

---

接下来是*Collections*里头的包装类怎么保证同步的，这里自己也没摸太清，简单说下：

可以看到包装类里的*synchronized*关键字都是给一个叫做*mutex*的变量加了锁，这个变量可以是调用*SynchronizedList(List list, Object mutex)*构造方法的时候传入——很遗憾我们不能调用这个构造方法↓↓↓

![](../PIC/集合-Collections类里不能调用的包装方法.png)

能去调用那个构造方法的包装方法是包可见的

既然我们不能自己传，*mutex*又已经被定义了。那就看下*mutex*变量从哪来的，*SynchronizedList*中我们并没有看到它的定义，于是去找父类*SynchronizedCollection*，在这我们看到了它：

```java
    final Collection<E> c;  // Backing Collection
    final Object mutex;     // Object on which to synchronize

    SynchronizedCollection(Collection<E> c) {
        this.c = Objects.requireNonNull(c);
        mutex = this;
    }

    SynchronizedCollection(Collection<E> c, Object mutex) {
        this.c = Objects.requireNonNull(c);
        this.mutex = Objects.requireNonNull(mutex);
    }
```

也就是说默认情况下，*mutex = this*

接下来就很清晰了：包装类里的方法，*synchronized*关键字是给当前包装类的对象加的锁

---

> 这里仅仅是以List作为说明，其实其他包装类和包装方法都大同小异了

# ConcurrentHashMap

> 因为从jdk1.7到jdk1.8，ConcurrentHashMap的改动相当大，这里都以jdk1.8来展开

ConcurrentHashMap是jdk1.5开始提供的一个支持多线程同步的HashMap容器，性能上比Hashtable这种古董货高好几个华莱士

简单来说，**ConcurrentHashMap保证多线程同步的机制是依靠*CAS*和*synchronized*关键字**

## 本体

```java
    transient volatile Node<K,V>[] table;

    static class Node<K,V> implements Map.Entry<K,V> {
        final int hash;
        final K key;
        volatile V val;
        volatile Node<K,V> next;
    }
```

和*HashMap*一样，*ConcurrentHashMap*也是由一个Node数组组成的，并且桶大小也只能为2的次方

在正常情况下，*ConcurrentHashMap*都是用链地址法处理冲突，*table*的每一个节点都是一个链表。当链表长度>8时，就会转换为红黑树

```java
    /**
     * 红黑树节点内部类
     */
    static final class TreeNode<K,V> extends Node<K,V> {
        TreeNode<K,V> parent;  // red-black tree links
        TreeNode<K,V> left;
        TreeNode<K,V> right;
        TreeNode<K,V> prev;    // needed to unlink next upon deletion
        boolean red;
    }

    /**
     * 在table数组中，存放的不是TreeNode而是这货（不像HashMap）。
     * 这个类并没有存放key-value，而是包装了红黑树，通过它访问红黑树
     * 同时还带了个读写锁
     */
    static final class TreeBin<K,V> extends Node<K,V> {
        TreeNode<K,V> root;
        volatile TreeNode<K,V> first;
        volatile Thread waiter;
        volatile int lockState;
        // values for lockState
        static final int WRITER = 1; // set while holding write lock
        static final int WAITER = 2; // set when waiting for write lock
        static final int READER = 4; // increment value for setting read lock
    }

    /**
     * TreeBin的hash值都为-2
     */
    static final int TREEBIN   = -2; // hash for roots of trees
```

#### 附带

*ForwardingNode*是*ConcurrentHashMap*扩容时使用到的一个类

它包含一个nextTable用于指向下一张表

```java
    static final class ForwardingNode<K,V> extends Node<K,V> {
        final Node<K,V>[] nextTable;

        ForwardingNode(Node<K,V>[] tab) {
            super(MOVED, null, null, null);
            this.nextTable = tab;
        }
    }

    /**
     * ForwardingNode的hash值都为-1
     */
    static final int MOVED     = -1; // hash for forwarding nodes
```

## 初始化

*ConcurrentHashMap*的构造方法使用上和*HashMap*差不多，属于一看签名就会用的那种

```java
    public ConcurrentHashMap(int initialCapacity,
                             float loadFactor, int concurrencyLevel) {
        if (!(loadFactor > 0.0f) || initialCapacity < 0 || concurrencyLevel <= 0)
            throw new IllegalArgumentException();
        if (initialCapacity < concurrencyLevel)   // Use at least as many bins
            initialCapacity = concurrencyLevel;   // as estimated threads
        long size = (long)(1.0 + (long)initialCapacity / loadFactor);
        int cap = (size >= (long)MAXIMUM_CAPACITY) ?
            MAXIMUM_CAPACITY : tableSizeFor((int)size);
        this.sizeCtl = cap;
    }

    public ConcurrentHashMap(Map<? extends K, ? extends V> m) {
        this.sizeCtl = DEFAULT_CAPACITY;
        putAll(m);
    }
```

同样，*ConcurrentHashMap*也会对传进来的*initialCapacity*进行处理，处理方式和*HashMap*一毛一样

会发现*initialCapacity*赋值给了*sizeCtl*

*ConcurrentHashMap*的桶数组也是在第一次往里面放东西的时候初始化，但是有专门的初始化方法。并且，初始化方法是可以在多线程环境下进行的：

```java
    private final Node<K,V>[] initTable() {
        Node<K,V>[] tab; int sc;
        while ((tab = table) == null || tab.length == 0) {
            // 首先会判断sizeCtl是否小于0，小于的话当前线程让出CPU时间
            // 而且没有争抢到初始化的线程会在这里一直自旋
            if ((sc = sizeCtl) < 0)
                Thread.yield(); // lost initialization race; just spin
            // 如果sizeCtl有小于0，CAS替换为-1
            // CAS操作成功了的话，代表这个线程争抢到了初始化数组的机会
            else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) {
                try {
                    // 这里将数组new出来
                    if ((tab = table) == null || tab.length == 0) {
                        int n = (sc > 0) ? sc : DEFAULT_CAPACITY;
                        @SuppressWarnings("unchecked")
                        Node<K,V>[] nt = (Node<K,V>[])new Node<?,?>[n];
                        table = tab = nt;
                        // sc = n * 0.75
                        sc = n - (n >>> 2);
                    }
                } finally {
                    // 这里可以看出来，sizeCtl保存了下一次扩容的阈值
                    sizeCtl = sc;
                }
                break;
            }
        }
        return tab;
    }
```

*initTable()*考虑到了可能会有多个线程进去的情况，因此巧妙的用CAS操作保证只能有一个线程修改*sizeCtl*成功，获取初始化数组的机会。其他线程则是让出CPU时间片，并且保持自旋，直到初始化成功退出方法

最后也可以看到，*sizeCtl*也保存了下一次扩容的阈值

## hash和定位

CHM的hash方法换了个名字

```java
    static final int spread(int h) {
        return (h ^ (h >>> 16)) & HASH_BITS;
    }
    
    static final int HASH_BITS = 0x7fffffff; // usable bits of normal node hash
```

和*HashMap*一样，高16位异或自己的低16位

但是多了一步，把最高位置0，这样保证hash出来的int是正数。因为<0的hash代表要不就是正在扩容，要不就是红黑树模式

对元素的定位上，CHM的定位方式和HM一样，都是取hash值的后几位（根据桶数组长度定）作为下标

## 同步控制

之前简单的提到过，*ConcurrentHashMap*保证多线程同步的机制是依靠CAS和*synchronized*关键字

CAS是无锁操作，并且jdk1.6之后，*synchronized*的性能有了大幅提升，因此*ConcurrentHashMap*放弃jdk1.7的同步控制方式大幅重写，也是情有可原的

关于CAS，*ConcurrentHashMap*定义了三个操作：

```java
    static final <K,V> Node<K,V> tabAt(Node<K,V>[] tab, int i) {
        return (Node<K,V>)U.getObjectVolatile(tab, ((long)i << ASHIFT) + ABASE);
    }

    static final <K,V> boolean casTabAt(Node<K,V>[] tab, int i,
                                        Node<K,V> c, Node<K,V> v) {
        return U.compareAndSwapObject(tab, ((long)i << ASHIFT) + ABASE, c, v);
    }

    static final <K,V> void setTabAt(Node<K,V>[] tab, int i, Node<K,V> v) {
        U.putObjectVolatile(tab, ((long)i << ASHIFT) + ABASE, v);
    }
```

*ConcurrentHashMap*便是使用了三个方法进行CAS

## get

通过key获取value的方法如下

```java
    public V get(Object key) {
        Node<K,V>[] tab; 
        Node<K,V> e, p; 
        int n, eh; 
        K ek;
        // 先获取到key的hashCode
        int h = spread(key.hashCode());
        // 先判断Map空不空，然后定位到下标，判断数组在下标位置是不是空
        // Map空或者定位到数组位置是空的话就返回null
        if ((tab = table) != null && (n = tab.length) > 0 &&
            (e = tabAt(tab, (n - 1) & h)) != null) {
            // 如果头节点就是要找的东西的话直接返回头节点了
            if ((eh = e.hash) == h) {
                if ((ek = e.key) == key || (ek != null && key.equals(ek)))
                    return e.val;
            }
            // 红黑树的情况
            else if (eh < 0)
                return (p = e.find(h, key)) != null ? p.val : null;
            // 链表的情况，就顺着链表下去找
            while ((e = e.next) != null) {
                if (e.hash == h &&
                    ((ek = e.key) == key || (ek != null && key.equals(ek))))
                    return e.val;
            }
        }
        return null;
    }
```

大体上还是蛮简单的

## put

```java
    public V put(K key, V value) {
        return putVal(key, value, false);
    }

    /** Implementation for put and putIfAbsent */
    final V putVal(K key, V value, boolean onlyIfAbsent) {
        // 不接受null的key
        if (key == null || value == null) throw new NullPointerException();
        // 获取hash
        int hash = spread(key.hashCode());

        int binCount = 0;

        // 一个死循环
        for (Node<K,V>[] tab = table;;) {
            Node<K,V> f; int n, i, fh;
            // 如果Map没有初始化的话先进行初始化
            if (tab == null || (n = tab.length) == 0)
                tab = initTable();
            // 如果数组中头节点为null，CAS插入节点
            // 失败了的话就重新循环了
            else if ((f = tabAt(tab, i = (n - 1) & hash)) == null) {
                if (casTabAt(tab, i, null,
                             new Node<K,V>(hash, key, value, null)))
                    break;                   // no lock when adding to empty bin
            }
            // 获取头节点的hash，如果是扩容状态，帮忙扩容
            else if ((fh = f.hash) == MOVED)
                tab = helpTransfer(tab, f);
            else {
                V oldVal = null;
                // 正常插入，这里使用synchronized上锁
                synchronized (f) {
                    // 二次确认数据有没有变动
                    if (tabAt(tab, i) == f) {
                        // hash>0的话说明是链表模式
                        if (fh >= 0) {
                            binCount = 1;
                            /*
                                这里顺着列表一直下去
                                当碰到相同的key时，将val替换
                                否则在尾部插一个新节点
                            */
                            for (Node<K,V> e = f;; ++binCount) {
                                K ek;
                                if (e.hash == hash &&
                                    ((ek = e.key) == key ||
                                     (ek != null && key.equals(ek)))) {
                                    oldVal = e.val;
                                    if (!onlyIfAbsent)
                                        e.val = value;
                                    break;
                                }
                                Node<K,V> pred = e;
                                if ((e = e.next) == null) {
                                    pred.next = 
                                        new Node<K,V>(hash, key, value, null);
                                    break;
                                }
                            }
                        }
                        // 红黑树模式
                        else if (f instanceof TreeBin) {
                            Node<K,V> p;
                            binCount = 2;
                            if ((p = ((TreeBin<K,V>)f).
                                    putTreeVal(hash, key, value)) != null) {
                                oldVal = p.val;
                                if (!onlyIfAbsent)
                                    p.val = value;
                            }
                        }
                    }
                }
                if (binCount != 0) {
                    // 如果链表长度达到TREEIFY_THRESHOLD就转换为红黑树
                    if (binCount >= TREEIFY_THRESHOLD)
                        treeifyBin(tab, i);
                    // 要不要返回旧的值
                    if (oldVal != null)
                        return oldVal;
                    break;
                }
            }
        }
        // 增加计数
        addCount(1L, binCount);
        return null;
    }
```

CHM的*put*方法和HM的*put*整体思路差不多。先通过hash定位到数组的下标，然后判断头节点是不是为空。如果头节点空，使用CAS进行插入，如果已经有数据了，用*synchronized*加锁，分链表、红黑树两种情况进行put操作。如果红黑树正在扩容，则协助扩容。

顺带一提，从方法一开头的判断看得出，**CHM是不接受key为null的**

## 扩容

你妈喊你回家填坑啦

